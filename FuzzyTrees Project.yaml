schemaVersion: 3
meta:
  sourceVersionId: f0943d76-a4f7-4923-8be6-6ce49c511155 # DO NOT CHANGE - Hex uses this to match up project versions when reimporting the file
  description: FuzzyTrees is a machine-learning application built in Python and Hex that combines fuzzy-matching techniques with a random forest classifier to do approximate matches on records from separate tables/data sources.
  projectId: 8a897f9f-9a20-4187-af68-c4109b682605 # DO NOT CHANGE - Unique ID of the project from which this file was generated
  title: FuzzyTrees Project
  timezone: null
  appTheme: SYS_PREF
  codeLanguage: PYTHON
  status: null
  categories: []
  castDecimalsDefault: true
  logicQueryCacheTimeout: null
  publishedQueryCacheTimeout: null
  hexType: PROJECT
  allowExecutionReordering: true
  prerunApp: false
  cachePublishedAppState: true
  refreshStalePublishedApp: false
  autoRerunApp: true
projectAssets:
  dataConnections: []
  envVars: []
  secrets: []
sharedAssets:
  secrets: []
  vcsPackages: []
  dataConnections: []
  externalFileIntegrations: []
cells:
  - cellType: INPUT
    cellId: 546f62c2-7248-44cc-82a0-43890beabb8d # DO NOT CHANGE - Hex uses this to match up cells when reimporting the file, and detect any changes to existing cells
    cellLabel: Run on seeds
    config:
      inputType: CHECKBOX
      name: run_on_seeds
      outputType: BOOLEAN
      options:
        style: switch
        text: ""
      defaultValue: false
  - cellType: INPUT
    cellId: 2df23529-9a8a-4f79-8271-80643eab90c5 # DO NOT CHANGE - Hex uses this to match up cells when reimporting the file, and detect any changes to existing cells
    cellLabel: Train random forest
    config:
      inputType: CHECKBOX
      name: train_random_forest
      outputType: BOOLEAN
      options:
        style: switch
        text: ""
      defaultValue: true
  - cellType: INPUT
    cellId: f027ce77-b557-449b-bb0f-123c612556b1 # DO NOT CHANGE - Hex uses this to match up cells when reimporting the file, and detect any changes to existing cells
    cellLabel: Table 1
    config:
      inputType: FILE_UPLOAD
      name: table_1
      outputType: DATA_FRAME
      options: null
      defaultValue: null
  - cellType: INPUT
    cellId: 2bccebf5-556f-4225-bfe9-dfafe36759f9 # DO NOT CHANGE - Hex uses this to match up cells when reimporting the file, and detect any changes to existing cells
    cellLabel: Table 2
    config:
      inputType: FILE_UPLOAD
      name: table_2
      outputType: DATA_FRAME
      options: null
      defaultValue: null
  - cellType: MARKDOWN
    cellId: e58f2792-f88d-4a1a-b07b-5d3f33afffb3 # DO NOT CHANGE - Hex uses this to match up cells when reimporting the file, and detect any changes to existing cells
    cellLabel: null
    config:
      source: <img src="/api/v1/file/2e334ab1-81a0-4125-92b1-ee1573ddb504" width="900" height="200"  />
  - cellType: MARKDOWN
    cellId: 308ab116-c4e4-45df-85b4-2ba438e54d3e # DO NOT CHANGE - Hex uses this to match up cells when reimporting the file, and detect any changes to existing cells
    cellLabel: null
    config:
      source: ""
  - cellType: MARKDOWN
    cellId: a85d0cc3-5447-4093-9e11-fa8a005d720b # DO NOT CHANGE - Hex uses this to match up cells when reimporting the file, and detect any changes to existing cells
    cellLabel: null
    config:
      source: |-
        FuzzyTrees is a machine-learning application built in Python and Hex that combines fuzzy-matching techniques with a random forest classifier to do approximate matches on records from separate tables/data sources. In the original use case, this was to find duplicate vet practice records that were flowing in through DBT from vso and vss data sources all the way into practice_online_details in the core layer. Duplicate records within our infrastructure can compromise the integrity of downstream reporting and analytics, which is why it's important to develop tools/strategies to avoid and handle duplicates.

        For all pairs of records in two tables, FuzzyTrees computes similarity metrics on shared fields (name, city, address, zip) using the <a href='https://en.wikipedia.org/wiki/Levenshtein_distance'>Levenshtein distance</a> and <a href='https://en.wikipedia.org/wiki/Jaro%E2%80%93Winkler_distance'>Jaro-Winkler distance</a>. These similarity metrics are 
        used for feature engineering for the random forest classifier algorithm. Scanning over duplicate VSS practices, FuzzyTrees finds the best approximate match in the table of VSO practices--providing a base mapping for systematic deduplication. 
  - cellType: CODE
    cellId: 10f06a3a-0de6-4092-b06d-cf32f29cd99d # DO NOT CHANGE - Hex uses this to match up cells when reimporting the file, and detect any changes to existing cells
    cellLabel: null
    config:
      source: |-
        # if train_random_forest:
        !pip install jellyfish
        import jellyfish as j
  - cellType: MARKDOWN
    cellId: a3a77da3-22d4-422d-a811-a4d8f7048044 # DO NOT CHANGE - Hex uses this to match up cells when reimporting the file, and detect any changes to existing cells
    cellLabel: null
    config:
      source: |-
        1. load dataset, 5000 matched vso/vss practices, 5000 unmatched practices. DONE
        2. Clean data (lower case everything, regexp non-alphanumerics) DONE
        3. Implement levenshtein and jaro winkler distances. DONE
        4. generate 8 point feature vector of similarity metrics for all pairs (5 Levenshtein, 5 Jaro Winkler) DONE
        5. train test split, train random forest classifier on 6000 pairs (3000 match, 3000 no-match), validation on 1000 points (500 match, 500 no-match), test on 1000 pairs (500 match, 500 no-match). 
        6. adjust hyperparams, etc. if necessary 
        7. report evaluation metrics 
        8. Algorithm for finding fuzzy-matches across vss / vso practices.
        8. front end, and communication 
  - cellType: CODE
    cellId: 2abb6ece-4b59-4df4-b048-0ccaeb1764b8 # DO NOT CHANGE - Hex uses this to match up cells when reimporting the file, and detect any changes to existing cells
    cellLabel: Iris Classification
    config:
      source: |
        import pandas as pd
        import matplotlib.pyplot as plt 
        import numpy as np 
        from sklearn.datasets import load_iris
        from sklearn.ensemble import RandomForestClassifier
        from sklearn.model_selection import train_test_split
        from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, confusion_matrix, roc_curve, auc
        import fuzzywuzzy as f
        from fuzzywuzzy import fuzz
        from joblib import dump, load
  - cellType: CODE
    cellId: 8045abbd-62e7-4c25-927f-d0dec43db7aa # DO NOT CHANGE - Hex uses this to match up cells when reimporting the file, and detect any changes to existing cells
    cellLabel: null
    config:
      source: ""
  - cellType: CODE
    cellId: cc2d6ad7-5ff3-456c-8a9c-da93f7ed5fc6 # DO NOT CHANGE - Hex uses this to match up cells when reimporting the file, and detect any changes to existing cells
    cellLabel:  Load Data
    config:
      source: |-
        
        if train_random_forest:
            og_pairs = pd.read_csv("training_data_zips.csv")
            pair_data = og_pairs
            pair_data.head()
  - cellType: CODE
    cellId: 61771901-7d5e-43e2-89ea-5a99b70c0728 # DO NOT CHANGE - Hex uses this to match up cells when reimporting the file, and detect any changes to existing cells
    cellLabel: Clean data (lower case everything, regexp non-alphanumerics)
    config:
      source: |-
        # convert all strings to lower case and remove spaces and commas. 
        if train_random_forest:
            pair_data.loc[:, pair_data.dtypes == 'object'] = pair_data.select_dtypes(['object']).apply(lambda x: x.str.lower())
            pair_data.loc[:, pair_data.dtypes == 'object'] = pair_data.select_dtypes(['object']).apply(lambda x: x.str.replace('[ ,-]', '', regex=True))
            pair_data.loc[:, pair_data.dtypes == 'object'] = pair_data.select_dtypes(['object']).apply(lambda x: x.str.replace('[&]', 'and', regex=True))
            pair_data['og_idx'] = pair_data.index
            pair_data = pair_data.sample(frac=1).reset_index(drop=True)
            pair_data.head()
        # pair_data = pair_data.iloc[1:10,:]
  - cellType: CODE
    cellId: 07aa1f44-ce1d-450e-bd1e-1cf82de4ffe5 # DO NOT CHANGE - Hex uses this to match up cells when reimporting the file, and detect any changes to existing cells
    cellLabel: define Levenshtein and Jaro Winkler Distances
    config:
      source: |-
        def jaro_winkler_distance(str1,str2):
            score = j.jaro_winkler_similarity(str1,str2)
            return score

        def levenshtein_distance(str1,str2):
            score = f.fuzz.ratio(str1, str2)/100
            return score
  - cellType: CODE
    cellId: df8443d0-275b-4ac9-8c6a-db77d1304091 # DO NOT CHANGE - Hex uses this to match up cells when reimporting the file, and detect any changes to existing cells
    cellLabel: null
    config:
      source: ""
  - cellType: CODE
    cellId: 4aece8ce-1523-4d42-a323-f3748b0750ff # DO NOT CHANGE - Hex uses this to match up cells when reimporting the file, and detect any changes to existing cells
    cellLabel: Generate Feature Vectors
    config:
      source: |-
        
        def generate_feature_vectors(columns_features,pair_data,distance_function):
            for jj in range(len(columns_features)):
                print("Creating feature vector for: " + columns_features[jj])
                distances = np.zeros((len(pair_data),1))
                for ii in range(len(pair_data)):
                    distance = distance_function(str(pair_data.iloc[ii,jj+1]),str(pair_data.iloc[ii,jj+6]))
                    distances[ii] = (distance)
                pair_data[columns_features[jj]] = distances
            return pair_data



        if train_random_forest:

            lev_features = ['name_lev_dist','city_lev_dist','address_lev_dist','zip_lev_dist'] 
            jaro_features = ['name_jaro_dist','city_jaro_dist','address_jaro_dist','zip_jaro_dist']
            pair_data = generate_feature_vectors(lev_features,pair_data,levenshtein_distance)
            pair_data = generate_feature_vectors(jaro_features,pair_data,jaro_winkler_distance)
            pair_data['TOTAL_SCORE'] = pair_data.iloc[:,-8:].sum(axis=1)
  - cellType: CODE
    cellId: 4feca621-7d92-453a-803e-7ca2edd9966c # DO NOT CHANGE - Hex uses this to match up cells when reimporting the file, and detect any changes to existing cells
    cellLabel: null
    config:
      source: |+
        lev_features = ['name_lev_dist','city_lev_dist','address_lev_dist','zip_lev_dist'] 
        jaro_features = ['name_jaro_dist','city_jaro_dist','address_jaro_dist','zip_jaro_dist']


        example = pd.read_csv("example.csv")

        example = generate_feature_vectors(lev_features,example,levenshtein_distance)
        example = generate_feature_vectors(jaro_features,example,jaro_winkler_distance)
        example['TOTAL_SCORE'] = example.iloc[:,-8:].sum(axis=1)

  - cellType: CODE
    cellId: fede126f-1dfc-4c33-a7cc-480716f7151f # DO NOT CHANGE - Hex uses this to match up cells when reimporting the file, and detect any changes to existing cells
    cellLabel: An Example
    config:
      source: example
  - cellType: MARKDOWN
    cellId: 7c131bad-3941-44c3-b3d8-5f0cf34e220f # DO NOT CHANGE - Hex uses this to match up cells when reimporting the file, and detect any changes to existing cells
    cellLabel: null
    config:
      source: |-
        Here is an example, the first row here is a matched pair of VSO and VSS practices. Scroll to the right on the table, you can see the engineered similatiy features, taking the Levenshtein and Jaro-Winkler-similarity measures (known as distances) with the name, city, address, and zip fields from the VSO and VSS practices, respectively. We take these 'fuzzy' similarity measures because we can't do an exact matching process for these records since the fields aren't exactly identical (one VSS practice may spell their address with "St.", the VSO practice spelling that same duplicated practice with "Street" instead). The specific distances have slightly different use cases--Jaro-Winkler is best for name matching, and texts with similar prefixes. Levenshtein is good for short texts, and for spelling corrections/typos. 

        These features tell us how similar the given fields are across the VSO and VSS data soures. We can observe that across the board for the first row, the name, city, address, and zipcodes between VSO and VSS data sources match perfectly, and so they obtain distance scores of 1. On the other hand, with the second row, the VSO and VSS practices do not match, and the similarity scores are much less than 1 across the board. 

        We cast the practice matching task as a binary classification problem, the algorithm should output 1 if the practices match, and 0 otherwise. The random forest classifier is a state of the art ML algorithm that averages a bunch of decision trees generated on subsamples of the data to determine this binary classification. In this sense, it determines how important each of these features are for the classification of a 'match'. For instance, it's okay if the addresses have slight differences (St. vs Street, etc.), but the zipcode should be a perfect match.
  - cellType: MARKDOWN
    cellId: b560f61d-5ca2-4780-826b-4310b2cf98ec # DO NOT CHANGE - Hex uses this to match up cells when reimporting the file, and detect any changes to existing cells
    cellLabel: null
    config:
      source: |-
        We used a dataset of ~3000 matching pairs of practices (verified manually) and ~3000 non-matching pairs of practices to train FuzzyTrees. 

        The validation set consists of ~1000 matching pairs of practices and ~1000 non-matching pairs of practices, it serves as a basis to understand the baseline generalizability of the model past the training data, and for tuning hyperparameters to improve performance--before testing predictions on the actual test set.

        The test set consists of ~1000 matching pairs of practices and ~1000 non-matching pairs of practices. The test set is used to evaluate the model's performance after it has been trained and validated. The key characteristic of the test set is that it is only used once, at the very end of the model development process, to provide an unbiased evaluation of the final model's performance. It simulates how the model would perform on unseen data in a real-world scenario.

        <!-- On the test set, FuzzyTrees achieves strong performance with the below accuracy, precision, and recall scores.  -->
  - cellType: CODE
    cellId: c77e0907-9e04-41a4-a5be-e6121acfa592 # DO NOT CHANGE - Hex uses this to match up cells when reimporting the file, and detect any changes to existing cells
    cellLabel: null
    config:
      source: pair_data
  - cellType: CODE
    cellId: 6af97742-3714-4263-b506-91187dc1ab08 # DO NOT CHANGE - Hex uses this to match up cells when reimporting the file, and detect any changes to existing cells
    cellLabel: Train Test Split, Random Forest on Training, Val, and Test 
    config:
      source: |-
        if train_random_forest:
            columns_features = ['og_idx','name_lev_dist','city_lev_dist','address_lev_dist','zip_lev_dist','name_jaro_dist','city_jaro_dist','address_jaro_dist','zip_jaro_dist','TOTAL_SCORE']
            feature_df = pair_data.loc[:,columns_features]
            target_df = pair_data.loc[:,'is_match']

            X = np.array(feature_df.iloc[:,1:])  # Features
            y = np.array(target_df)  # Target variable

            # First, split the data into training + validation set and test set
            X_train_val, X_test, y_train_val, y_test = train_test_split(X, y, test_size=0.2, random_state=1)

            # Now, split the training + validation set into training and validation sets
            X_train, X_val, y_train, y_val = train_test_split(X_train_val, y_train_val, test_size=0.25, random_state=1)
            
            # Initialize the Random Forest classifier
            random_forest_classifier = RandomForestClassifier(n_estimators=200, random_state=1)

            # Fit the model on the training data
            random_forest_classifier.fit(X_train, y_train)

            # Predict the labels of the test set
            y_pred = random_forest_classifier.predict(X_val)
            y_pred_test = random_forest_classifier.predict(X_test)

            # # Calculate the accuracy of the model
            # accuracy = accuracy_score(y_test, y_pred)
            # print(f"Model Accuracy: {accuracy*100:.5f}%")
  - cellType: CODE
    cellId: c915a0d4-b735-4a3d-9fad-12183fc5f249 # DO NOT CHANGE - Hex uses this to match up cells when reimporting the file, and detect any changes to existing cells
    cellLabel: null
    config:
      source: |
        import plotly.graph_objects as go
  - cellType: CODE
    cellId: abb50efb-7f8c-47ab-92a1-bcec9a420722 # DO NOT CHANGE - Hex uses this to match up cells when reimporting the file, and detect any changes to existing cells
    cellLabel: null
    config:
      source: y_test.sum()
  - cellType: CODE
    cellId: 501f5a49-e9d7-456c-af29-80307686d833 # DO NOT CHANGE - Hex uses this to match up cells when reimporting the file, and detect any changes to existing cells
    cellLabel: null
    config:
      source: |
        if train_random_forest:
            # Accuracy
            accuracy = accuracy_score(y_val, y_pred)
            print(f'Validation Set Accuracy: {accuracy:.5f}')

            # Precision
            precision = precision_score(y_val, y_pred)
            print(f'Validation Set Precision: {precision:.5f}')

            # Recall
            recall = recall_score(y_val, y_pred)
            print(f'Validation Set Recall: {recall:.5f}')

            # F1 Score
            f1 = f1_score(y_val, y_pred)
            print(f'Validation Set F1 Score: {f1:.5f}')

            # ROC-AUC
            roc_auc = roc_auc_score(y_val, y_pred)
            print(f'Validation Set ROC-AUC: {roc_auc:.5f}')

            # Confusion Matrix
            cm = confusion_matrix(y_val, y_pred)
            print('Validation Set Confusion Matrix:')
            print(cm)

            # Optionally, plot ROC curve
            import matplotlib.pyplot as plt

            fpr, tpr, _ = roc_curve(y_val, y_pred)
            roc_auc = auc(fpr, tpr)

            fig = go.Figure()

            # Plot ROC curve
            fig.add_trace(go.Scatter(x=fpr, y=tpr,
                                mode='lines',
                                name=f'ROC curve (area = {roc_auc:.5f})',
                                line=dict(color='darkorange', width=2)))

            # Plot diagonal line
            fig.add_trace(go.Scatter(x=[0, 1], y=[0, 1],
                                mode='lines',
                                name='Random Guessing',
                                line=dict(color='navy', width=2, dash='dash')))

            # Set layout
            fig.update_layout(
                xaxis_title='False Positive Rate',
                yaxis_title='True Positive Rate',
                title='Validation Set ROC',
                xaxis=dict(range=[0, 1]),
                yaxis=dict(range=[0, 1.05]),
                legend=dict(x=0.02, y=0.98),
            )

            fig.show()
            
            # Accuracy
            accuracy = accuracy_score(y_test, y_pred_test)
            print(f'Test Set Accuracy: {accuracy:.5f}')

            # Precision
            precision = precision_score(y_test, y_pred_test)
            print(f'Test Set Precision: {precision:.5f}')

            # Recall
            recall = recall_score(y_test, y_pred_test)
            print(f'Test Set Recall: {recall:.5f}')

            # F1 Score
            f1 = f1_score(y_test, y_pred_test)
            print(f'Test Set F1 Score: {f1:.5f}')

            # ROC-AUC
            roc_auc = roc_auc_score(y_test, y_pred_test)
            print(f'Test Set ROC-AUC: {roc_auc:.5f}')

            # Confusion Matrix
            cm = confusion_matrix(y_test, y_pred_test)
            print('Test Set Confusion Matrix:')
            print(cm)

            fpr, tpr, _ = roc_curve(y_test, y_pred_test)
            roc_auc = auc(fpr, tpr)


            fig = go.Figure()

            # Plot ROC curve
            fig.add_trace(go.Scatter(x=fpr, y=tpr,
                                mode='lines',
                                name=f'ROC curve (area = {roc_auc:.5f})',
                                line=dict(color='darkorange', width=2)))

            # Plot diagonal line
            fig.add_trace(go.Scatter(x=[0, 1], y=[0, 1],
                                mode='lines',
                                name='Random Guessing',
                                line=dict(color='navy', width=2, dash='dash')))

            # Set layout
            fig.update_layout(
                xaxis_title='False Positive Rate',
                yaxis_title='True Positive Rate',
                title='Test Set ROC',
                xaxis=dict(range=[0, 1]),
                yaxis=dict(range=[0, 1.05]),
                legend=dict(x=0.02, y=0.98),
            )

            fig.show()
  - cellType: MARKDOWN
    cellId: be7c7af3-c525-4c3f-a690-f58c9b5fc8cf # DO NOT CHANGE - Hex uses this to match up cells when reimporting the file, and detect any changes to existing cells
    cellLabel: null
    config:
      source: |
        #### Are these metrics too good to be true?

        - While fuzzy-matching tasks are difficult in general--the data is not excessively noisy here--and the differences between fields often reflect point edits, capitalization differences, and alternative spelling. 

        The random forest algorithm is very well-suited to this dataset and task, particularly when we give it two robust fuzzy-measures of string similarity on the fields as features. Very high performance metrics can be expected in this case, and are necessary in order to ensure exhaustive and correct de-duplication. That being said, the validation and test sets are defined using the same VSO/VSS practice-matching use case, and a futher exploration would be to apply FuzzyTrees to a different matching use case and see how the performance generalizes.

        #### What exactly are these evaluation metrics and plots above? 


        ### Accuracy
        - **What it measures:** The proportion of all matches that the model got right.
        - **How to calculate:** It's the number of correct predictions divided by the total number of predictions.
        - **Use case:** Good for an overall sense of how often the model is correct, but can be misleading if the classes are imbalanced (e.g., 95% of the data is of one class).

        ### Precision
        - **What it measures:** The proportion of positive classifications that were actually correct.
        - **How to calculate:** It's the number of true matches divided by the total number of positive predictions (true positives + false positives).
        - **Use case:** Useful when the cost of a false positive is high. For example, in email spam detection, you'd want to be really sure an email is spam before filtering it out. 

        ### Recall (Sensitivity)
        - **What it measures:** The proportion of actual positive matches that were identified correctly.
        - **How to calculate:** It's the number of true positive predictions divided by the total number of actual positives (true positives + false negatives).
        - **Use case:** Important when the cost of a false negative is high. For example, in disease screening, you wouldn’t want to miss diagnosing a person with the disease. In our case, we need to make sure we aren't missing any matching practices because then we won't be able to de-duplicate them from practice_online_details! 

        ### F1-Score
        - **What it measures:** The balance between precision and recall.
        - **How to calculate:** It's the harmonic mean of precision and recall, giving both metrics equal weight. Calculated as 2 * (precision * recall) / (precision + recall).
        - **Use case:** Useful when you need a balance between precision and recall and there’s an uneven class distribution. It’s more informative than accuracy in cases of imbalanced classes.

        ### ROC (Receiver Operating Characteristic) Score and AUC (Area Under the ROC Curve)
        - **What they measure:** The ROC curve plots the true positive rate (recall) against the false positive rate for different classification thresholds. The AUC (Area Under the Curve) measures the entire two-dimensional area underneath the ROC curve from (0,0) to (1,1).
        - **How to calculate:** The ROC score is not a single number but a plot. The AUC can be calculated based on the plot, with a value of 1 representing a perfect model and a value of 0.5 representing a model that does no better than random chance.
        - **Use case:** Very useful for evaluating the performance of a binary classifier, especially in cases of imbalanced datasets. It gives an idea of how well the model is able to distinguish between classes.
  - cellType: CODE
    cellId: 2a3fc275-b786-4589-9c7a-ac0d7b566083 # DO NOT CHANGE - Hex uses this to match up cells when reimporting the file, and detect any changes to existing cells
    cellLabel: Feature Importance Plot
    config:
      source: |
        
        if train_random_forest:
            # Get the feature importances
            feature_importances = random_forest_classifier.feature_importances_

            # Optionally, you can sort the features by importance
            sorted_idx = feature_importances.argsort()

            # Plotting the feature importances
            plt.figure(figsize=(10, 6))
            plt.barh(range(len(sorted_idx)), feature_importances[sorted_idx], align='center')
            plt.yticks(range(len(sorted_idx)), [f"Feature {feature_df.columns[i+1]}" for i in sorted_idx])
            plt.xlabel("Feature Importance")
            plt.title("Feature Importance in Random Forest Model")
            plt.show()
  - cellType: MARKDOWN
    cellId: 830123f4-ade3-418b-8e41-9c8baa0e4821 # DO NOT CHANGE - Hex uses this to match up cells when reimporting the file, and detect any changes to existing cells
    cellLabel: null
    config:
      source: |-
        ### What is this feature importance plot?

        A feature importance plot is a visual representation used in machine learning to show the relative importance or contribution of each feature to the model's predictions. This plot helps to identify which features (variables or inputs) are most influential in determining the outcome of the random forest classifier. It shows that zip code under the Levenshtein distance is the most important feature for determining the classification, as expected--then name and zip under Jaro distance.

        Understanding Influence: It shows which features have the most impact on the model's predictions. This can be crucial for understanding the underlying dynamics of the model, especially in complex models where the decision-making process is not inherently transparent.

        Simplification and Focus: By identifying the most important features, you can potentially simplify the model by removing features that contribute little to no predictive power, making the model faster and more efficient without significantly compromising accuracy.
  - cellType: CODE
    cellId: b152683c-f978-4a5c-8629-689cd0b29bb7 # DO NOT CHANGE - Hex uses this to match up cells when reimporting the file, and detect any changes to existing cells
    cellLabel: null
    config:
      source: "# pair_data.head()"
  - cellType: CODE
    cellId: 934037ad-89fd-459a-9c40-72632f7330fb # DO NOT CHANGE - Hex uses this to match up cells when reimporting the file, and detect any changes to existing cells
    cellLabel: FuzzyTrees on VSO vs VSS dataset
    config:
      source: |-
        
        if run_on_seeds:
            print("Running on all practices..")
            df_vso = pd.read_csv("vso_unmatched.csv")
            df_vss = pd.read_csv("vss_unmatched.csv")
            gt_matches = pd.read_csv("ground_truth_matches.csv")


            total_vso_ids = len(df_vso)
            match_table = pd.DataFrame(np.zeros((7000,11)),columns=['vss_odu_id', 'vss_name', 'vss_address', 'vss_city', 'vss_zip', 'vso_odu_id', 'vso_name', 'vso_address', 'vso_city', 'vso_zip','total_score'])
            table_idx = 0
            # for ii in range(22,len(df_vss)):

            for ii in range(22,24):
                print(ii)
                tmp_vss_df = df_vss.iloc[ii,:]
                # Repeat the row N times
                duplicates = pd.concat([tmp_vss_df]*total_vso_ids, axis=1).transpose()
                # Append duplicates to the original DataFrame
                tmp_vss_df = pd.concat([duplicates], ignore_index=True)
                tmp_merged_df = pd.concat([tmp_vss_df,df_vso],axis=1)

                lev_features = ['name_lev_dist','city_lev_dist','address_lev_dist','zip_lev_dist'] 
                jaro_features = ['name_jaro_dist','city_jaro_dist','address_jaro_dist','zip_jaro_dist']
                tmp_merged_df = generate_feature_vectors(lev_features,tmp_merged_df,levenshtein_distance)
                tmp_merged_df = generate_feature_vectors(jaro_features,tmp_merged_df,jaro_winkler_distance)
                columns_features = ['name_lev_dist','city_lev_dist','address_lev_dist','zip_lev_dist','name_jaro_dist','city_jaro_dist','address_jaro_dist','zip_jaro_dist']
                tmp_merged_df['TOTAL_SCORE'] = tmp_merged_df.loc[:,columns_features].sum(axis=1)
                columns_features  = ['name_lev_dist','city_lev_dist','address_lev_dist','zip_lev_dist','name_jaro_dist','city_jaro_dist','address_jaro_dist','zip_jaro_dist','TOTAL_SCORE']
                feature_df = tmp_merged_df.loc[:,columns_features]
                X = np.array(feature_df)  # Features

                y_pred = random_forest_classifier.predict(X)

                indices = np.where(y_pred == 1)[0]
                if len(indices) != 0:
                    tmp_df2 = tmp_merged_df.loc[indices,columns_features]
                    tmp_df2['summed'] = tmp_df2.sum(axis=1)
                    max_index = tmp_df2['summed'].idxmax()

                    match_table.iloc[table_idx,0:10] = tmp_merged_df.iloc[int(max_index),0:10]
                    match_table.iloc[table_idx,10] = tmp_merged_df.loc[int(max_index),'TOTAL_SCORE']
                    table_idx += 1    
                else:
                    pass    

            match_table
            match_table.to_csv("match_outputs.csv")
  - cellType: CODE
    cellId: 7d719524-54cc-48be-98c5-a6961064b5b1 # DO NOT CHANGE - Hex uses this to match up cells when reimporting the file, and detect any changes to existing cells
    cellLabel: null
    config:
      source: |-
        # match_table
        # Save your model to a file
        dump(random_forest_classifier, 'random_forest_model.joblib')
  - cellType: CODE
    cellId: 9bb6b965-ec4d-41ae-bc08-98ac27b6bb33 # DO NOT CHANGE - Hex uses this to match up cells when reimporting the file, and detect any changes to existing cells
    cellLabel: null
    config:
      source: |-
        # Load the model from the file
        # clf = load('random_forest_model.joblib')
  - cellType: CODE
    cellId: a5dcc548-1612-441b-a032-83b84e7f4b70 # DO NOT CHANGE - Hex uses this to match up cells when reimporting the file, and detect any changes to existing cells
    cellLabel: null
    config:
      source: random_forest_classifier
appLayout:
  visibleMetadataFields:
    - NAME
    - DESCRIPTION
    - AUTHOR
    - LAST_EDITED
    - LAST_RUN
    - CATEGORIES
    - STATUS
    - TABLE_OF_CONTENTS
  fullWidth: false
  tabs:
    - name: Tab 1
      rows:
        - columns:
            - start: 0
              end: 120
              elements:
                - showSource: false
                  hideOutput: false
                  type: CELL
                  cellId: 2df23529-9a8a-4f79-8271-80643eab90c5
                  sharedFilterId: null
                  height: null
                  showLabel: true
        - columns:
            - start: 0
              end: 120
              elements:
                - showSource: false
                  hideOutput: false
                  type: CELL
                  cellId: e58f2792-f88d-4a1a-b07b-5d3f33afffb3
                  sharedFilterId: null
                  height: 200
                  showLabel: true
        - columns:
            - start: 0
              end: 120
              elements:
                - showSource: false
                  hideOutput: false
                  type: CELL
                  cellId: 308ab116-c4e4-45df-85b4-2ba438e54d3e
                  sharedFilterId: null
                  height: 150
                  showLabel: true
        - columns:
            - start: 0
              end: 120
              elements:
                - showSource: false
                  hideOutput: false
                  type: CELL
                  cellId: a85d0cc3-5447-4093-9e11-fa8a005d720b
                  sharedFilterId: null
                  height: null
                  showLabel: true
        - columns:
            - start: 0
              end: 120
              elements:
                - showSource: false
                  hideOutput: false
                  type: CELL
                  cellId: b560f61d-5ca2-4780-826b-4310b2cf98ec
                  sharedFilterId: null
                  height: null
                  showLabel: true
        - columns:
            - start: 0
              end: 120
              elements:
                - showSource: false
                  hideOutput: false
                  type: CELL
                  cellId: 4aece8ce-1523-4d42-a323-f3748b0750ff
                  sharedFilterId: null
                  height: null
                  showLabel: true
        - columns:
            - start: 0
              end: 120
              elements:
                - showSource: false
                  hideOutput: false
                  type: CELL
                  cellId: fede126f-1dfc-4c33-a7cc-480716f7151f
                  sharedFilterId: null
                  height: null
                  showLabel: true
        - columns:
            - start: 0
              end: 120
              elements:
                - showSource: false
                  hideOutput: false
                  type: CELL
                  cellId: 7c131bad-3941-44c3-b3d8-5f0cf34e220f
                  sharedFilterId: null
                  height: null
                  showLabel: true
        - columns:
            - start: 0
              end: 120
              elements:
                - showSource: false
                  hideOutput: false
                  type: CELL
                  cellId: 6af97742-3714-4263-b506-91187dc1ab08
                  sharedFilterId: null
                  height: null
                  showLabel: true
        - columns:
            - start: 0
              end: 120
              elements:
                - showSource: false
                  hideOutput: false
                  type: CELL
                  cellId: 501f5a49-e9d7-456c-af29-80307686d833
                  sharedFilterId: null
                  height: null
                  showLabel: true
        - columns:
            - start: 0
              end: 120
              elements:
                - showSource: false
                  hideOutput: false
                  type: CELL
                  cellId: be7c7af3-c525-4c3f-a690-f58c9b5fc8cf
                  sharedFilterId: null
                  height: null
                  showLabel: true
        - columns:
            - start: 0
              end: 120
              elements:
                - showSource: false
                  hideOutput: false
                  type: CELL
                  cellId: 2a3fc275-b786-4589-9c7a-ac0d7b566083
                  sharedFilterId: null
                  height: null
                  showLabel: true
        - columns:
            - start: 0
              end: 120
              elements:
                - showSource: false
                  hideOutput: false
                  type: CELL
                  cellId: 830123f4-ade3-418b-8e41-9c8baa0e4821
                  sharedFilterId: null
                  height: null
                  showLabel: true
        - columns:
            - start: 0
              end: 120
              elements:
                - showSource: false
                  hideOutput: false
                  type: CELL
                  cellId: 934037ad-89fd-459a-9c40-72632f7330fb
                  sharedFilterId: null
                  height: null
                  showLabel: true
sharedFilters: []
